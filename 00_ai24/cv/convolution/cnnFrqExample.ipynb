{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Frequency Estimation Problem \n",
    "\n",
    "explore a basic example of using a Convolutional Neural Network (CNN) to solve a frequency estimation problem. This type of problem involves estimating the frequency of a signal from input data, which is common in signal processing and time-series analysis.\n",
    "\n",
    "#### Problem Description\n",
    "\n",
    "Given a series of input signals, the goal is to estimate the frequency of each signal. This is particularly useful in applications like audio signal processing, where identifying the frequency can help in recognizing musical notes, speech processing, and other tasks.\n",
    "\n",
    "#### Model Architecture\n",
    "\n",
    "A basic CNN architecture for this problem typically consists of the following layers:\n",
    "\n",
    "1. **Input Layer**: This layer accepts the raw signal data. For simplicity, assume the input signals are 1D arrays.\n",
    "\n",
    "2. **Convolutional Layers**: These layers apply convolutional filters to the input signal to extract relevant features. Each filter slides over the input signal to detect patterns. Common configurations include:\n",
    "   - **Number of Filters**: Determines how many different features are learned.\n",
    "   - **Filter Size**: Defines the size of the filters that slide over the input signal.\n",
    "   - **Stride**: Specifies how much the filter moves at each step.\n",
    "   - **Padding**: Decides whether the input signal is padded to maintain the same output size.\n",
    "\n",
    "3. **Pooling Layers**: These layers reduce the dimensionality of the feature maps, typically using max pooling. This helps in reducing the computational complexity and extracting dominant features.\n",
    "\n",
    "4. **Fully Connected Layers**: After several convolutional and pooling layers, the output is flattened and passed through one or more fully connected layers. These layers act as a classifier or a regressor depending on the task.\n",
    "\n",
    "5. **Output Layer**: For frequency estimation, the output layer typically has one neuron with a linear activation function to predict the frequency.\n",
    "\n",
    "#### Loss Function\n",
    "\n",
    "The loss function used in this example is the Root Mean Squared Error (RMSE). RMSE measures the average magnitude of the errors between predicted and actual frequencies, providing a clear indication of the model's performance.\n",
    "\n",
    "\\[\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "\\]\n",
    "\n",
    "\n",
    "where \\( y_i \\) is the actual frequency, \\( \\hat{y}_i \\) is the predicted frequency, and \\( n \\) is the number of samples.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Error (RMSE)\n",
    "\n",
    "Root Mean Square Error (RMSE) is a widely used metric to measure the accuracy of a predictive model. It represents the square root of the average of the squared differences between predicted values and actual values. Here's a breakdown of what this means:\n",
    "\n",
    "#### Understanding RMSE\n",
    "\n",
    "1. **Error Calculation**: For each prediction made by the model, calculate the difference between the predicted value and the actual value. This difference is known as the error.\n",
    "\n",
    "2. **Square the Errors**: Each error is squared to ensure all values are positive, emphasizing larger errors more than smaller ones.\n",
    "\n",
    "3. **Average the Squared Errors**: Compute the mean (average) of these squared errors. This gives an overall measure of the model's error, known as Mean Squared Error (MSE).\n",
    "\n",
    "4. **Square Root**: Finally, take the square root of the MSE to return to the original units of the predicted values. This is the RMSE.\n",
    "\n",
    "#### Mathematical Representation\n",
    "\n",
    "The RMSE is mathematically represented as:\n",
    "\n",
    "\\[ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} \\]\n",
    "\n",
    "where:\n",
    "- \\( n \\) is the number of observations.\n",
    "- \\( y_i \\) is the actual value.\n",
    "- \\( \\hat{y}_i \\) is the predicted value.\n",
    "\n",
    "#### Key Points\n",
    "\n",
    "- **Unit Consistency**: RMSE has the same units as the predicted values, making it easier to interpret and compare.\n",
    "- **Sensitivity to Outliers**: Due to squaring the errors, RMSE is particularly sensitive to outliers. Large errors have a disproportionately large impact on the RMSE.\n",
    "- **Model Evaluation**: A lower RMSE indicates a better fit of the model to the data, meaning the predictions are closer to the actual values.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "RMSE is a crucial metric for assessing the performance of regression models. It provides a clear measure of how well the model's predictions match the actual data, with lower values indicating better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Generate synthetic data for the example\n",
    "def generate_synthetic_data(num_samples, length):\n",
    "    X = np.random.randn(num_samples, length)\n",
    "    y = np.random.uniform(low=0.1, high=10.0, size=num_samples)\n",
    "    return X, y\n",
    "\n",
    "# Prepare data\n",
    "num_samples = 1000\n",
    "length = 100\n",
    "X_train, y_train = generate_synthetic_data(num_samples, length)\n",
    "X_test, y_test = generate_synthetic_data(num_samples // 10, length)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(length, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=MeanSquaredError(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, rmse = model.evaluate(X_test, y_test)\n",
    "print(f'Test RMSE: {rmse}')\n",
    "\n",
    "# Predicting on new data\n",
    "predictions = model.predict(X_test[:5])\n",
    "print(f'Predicted frequencies: {predictions.flatten()}')\n",
    "```\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "1. **Data Generation**: Synthetic data is generated to simulate the frequency estimation problem. The signals (`X`) are random noise, and the frequencies (`y`) are uniformly distributed between 0.1 and 10.0.\n",
    "2. **Model Building**: A sequential model is built with two convolutional layers, each followed by a max-pooling layer. The output is flattened and passed through a dense layer to produce the final frequency prediction.\n",
    "3. **Training**: The model is compiled with the Adam optimizer and Mean Squared Error loss function, then trained on the synthetic data.\n",
    "4. **Evaluation**: The model's performance is evaluated on a test set, and the Root Mean Squared Error (RMSE) is printed.\n",
    "5. **Prediction**: The model makes predictions on new data to demonstrate its frequency estimation capability.\n",
    "\n",
    "This example provides a foundation for understanding how CNNs can be applied to frequency estimation problems. The architecture and parameters can be further tuned based on specific requirements and data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
