

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>sota - state-of-the-art &#8212; solAiKM</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '00_ai24/cv/infer/sota';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="zoo(s)" href="zoo.html" />
    <link rel="prev" title="pytorch Inference" href="pyInter.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../readme.html">
  
  
  
  
  
  
    <p class="title logo__title">solAiKM</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../readme.html">
                    solai
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">AI24</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../readme.html">AI Computer Vision</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../convolution/fullyConnectedDrawback.html">Fully Connected Drawbacks</a></li>

<li class="toctree-l2"><a class="reference internal" href="../convolution/cnnFrqExample.html">CNN for Frequency Estimation Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convolution/0085DeepLearning1DConvFreqEst.html">Convolution for Frequency Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convolution/readme.html">Convolution in Deep Learning</a></li>

<li class="toctree-l2"><a class="reference internal" href="../convolution/2d.html">2D Convolution</a></li>





<li class="toctree-l2"><a class="reference internal" href="../convolution/layers.html">Layers in Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convolution/pooling.html">Pooling in Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convolution/batchNorm.html">Batch Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convolution/lab_batchNorm.html">demo batch norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convolution/filters.html">Common Filters for 2D Convolution</a></li>

<li class="toctree-l2"><a class="reference internal" href="../convolution/filter_laplacian.html">Common Filters for 2D Convolution</a></li>

<li class="toctree-l2"><a class="reference internal" href="../pytorch/common.html">pytorch layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/custom.html">custom nn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/microMacro.html">micro macro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../torchvis/readme.html">TorchVision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../torchvis/transformVers.html">torchvision.transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concept/recfield.html">Receptive Field (RF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concept/recField.html">Calc RF</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concept/encodeDecode.html">Encode-Decode Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concept/skipConnections.html">skip connections</a></li>
<li class="toctree-l2"><a class="reference internal" href="../augm/readme.html">Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../augm/0094DeepLearningImageAugmentation.html">Image Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../augm/cutMethods.html">Cut Effects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../augm/0095DeepLearningImageAugmentation.html">Image Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../augm/smoothing.html">Smoothing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../augm/0096DeepLearningLabelSmoothing.html">Label Smoothing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../augm/0097DeepLearningRegularizedTraining.html">Regularized Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convolution/0086DeepLearningConv2DCifar10.html">cifar10-2d-convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convolution/0087DeepLearningConv2DFashionMNIST.html">Image Classification Fashion MNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="../arch/readme.html">compare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../arch/darknet53.html">darknet53</a></li>
<li class="toctree-l2"><a class="reference internal" href="../arch/alexnet.html">AlexNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../arch/vgg.html">vgg</a></li>

<li class="toctree-l2"><a class="reference internal" href="../arch/googleNet.html">googleNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../arch/inception.html">Inception Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../arch/resnet.html">resnet</a></li>

<li class="toctree-l2"><a class="reference internal" href="../arch/0092DeepLearningResNet.html">ResNet Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../arch/yolo.html">yolo</a></li>

<li class="toctree-l2"><a class="reference internal" href="../arch/minirocket.html">minirocket</a></li>

<li class="toctree-l2"><a class="reference internal" href="../arch/lab_minirocket_basicDemo.html">lab simple minirocket demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="readme.html">Pre-Defined Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="pyInter.html">pytorch Inference</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">sota - state-of-the-art</a></li>
<li class="toctree-l2"><a class="reference internal" href="zoo.html">zoo(s)</a></li>
<li class="toctree-l2"><a class="reference internal" href="0091DeepLearningPreTrainedModels.html">Pre Trained Computer Vision Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transf/readme.html">Transfer Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transf/compare.html">compare methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transf/fineTune.html">Fine-Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transf/freeze.html">Freeze Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transf/0093DeepLearningTransferLearning.html">Transfer Learning of resnet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transf/overfit.html">Transfer overfit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transf/transformers.html">transformers</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/SOLEROM/solai" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/SOLEROM/solai/issues/new?title=Issue%20on%20page%20%2F00_ai24/cv/infer/sota.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/00_ai24/cv/infer/sota.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>sota - state-of-the-art</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lr-optimizations">LR Optimizations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trivialaugment">TrivialAugment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#long-training">Long Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-erasing">Random Erasing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#label-smoothing">Label Smoothing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixup">Mixup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cutmix">Cutmix</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weight-decay-tuning">Weight Decay Tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fixres-mitigations">FixRes Mitigations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ema-exponential-moving-average">EMA (Exponential Moving Average)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-resize-tuning">Inference Resize Tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#repeated-augmentation">Repeated Augmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-normalization">Batch Normalization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dropout">Dropout</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-clipping">Gradient Clipping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">Transfer Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cosine-annealing">Cosine Annealing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#early-stopping">Early Stopping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#warmup-learning-rate">Warmup Learning Rate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-distillation">Knowledge Distillation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation">Data Augmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoaugment">AutoAugment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-depth">Stochastic Depth</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ghost-batch-normalization">Ghost Batch Normalization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#label-propagation">Label Propagation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-accumulation">Gradient Accumulation</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="sota-state-of-the-art">
<h1>sota - state-of-the-art<a class="headerlink" href="#sota-state-of-the-art" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/">https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/</a></p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">+</span> <span class="n">LR</span> <span class="n">optimizations</span> 	
<span class="o">+</span> <span class="n">TrivialAugment</span> 	
<span class="o">+</span> <span class="n">Long</span> <span class="n">Training</span> 	
<span class="o">+</span> <span class="n">Random</span> <span class="n">Erasing</span> 	
<span class="o">+</span> <span class="n">Label</span> <span class="n">Smoothing</span> 
<span class="o">+</span> <span class="n">Mixup</span> 	
<span class="o">+</span> <span class="n">Cutmix</span> 	
<span class="o">+</span> <span class="n">Weight</span> <span class="n">Decay</span> <span class="n">tuning</span> 	
<span class="o">+</span> <span class="n">FixRes</span> <span class="n">mitigations</span> 	
<span class="o">+</span> <span class="n">EMA</span> 	
<span class="o">+</span> <span class="n">Inference</span> <span class="n">Resize</span> <span class="n">tuning</span> 
<span class="o">+</span> <span class="n">Repeated</span> <span class="n">Augmentation</span> 
</pre></div>
</div>
<section id="lr-optimizations">
<h2>LR Optimizations<a class="headerlink" href="#lr-optimizations" title="Permalink to this heading">#</a></h2>
<p><strong>Learning Rate (LR) Optimization</strong> involves adjusting the learning rate during training to improve convergence and performance. Techniques like learning rate schedules, warm restarts, and adaptive learning rates (e.g., using optimizers like Adam, RMSprop) help in finding a better minimum of the loss function.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: Proper LR adjustments prevent the model from getting stuck in local minima and ensure faster and more stable convergence.</p></li>
</ul>
</section>
<section id="trivialaugment">
<h2>TrivialAugment<a class="headerlink" href="#trivialaugment" title="Permalink to this heading">#</a></h2>
<p><strong>TrivialAugment</strong> is a simple data augmentation technique that applies a random transformation from a predefined set of augmentations to the input data.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: By introducing random variations, the model becomes more robust to changes and improves generalization.</p></li>
</ul>
</section>
<section id="long-training">
<h2>Long Training<a class="headerlink" href="#long-training" title="Permalink to this heading">#</a></h2>
<p><strong>Long Training</strong> refers to extending the training duration, often with a smaller learning rate, to allow the model to fine-tune its parameters more precisely.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: Prolonged training with a reduced learning rate can lead to better convergence and improved performance.</p></li>
</ul>
</section>
<section id="random-erasing">
<h2>Random Erasing<a class="headerlink" href="#random-erasing" title="Permalink to this heading">#</a></h2>
<p><strong>Random Erasing</strong> is a data augmentation technique where random patches of input images are masked out during training.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: This makes the model more resilient to missing parts of the image, improving robustness and generalization.</p></li>
</ul>
</section>
<section id="label-smoothing">
<h2>Label Smoothing<a class="headerlink" href="#label-smoothing" title="Permalink to this heading">#</a></h2>
<p><strong>Label Smoothing</strong> involves softening the labels by assigning a small probability to all classes instead of assigning a probability of 1 to the correct class and 0 to others.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It prevents the model from becoming overconfident, leading to better calibration and improved generalization.</p></li>
</ul>
</section>
<section id="mixup">
<h2>Mixup<a class="headerlink" href="#mixup" title="Permalink to this heading">#</a></h2>
<p><strong>Mixup</strong> creates new training examples by combining pairs of examples and their labels with a certain mixing ratio.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: This encourages the model to behave linearly in-between training examples, improving robustness and generalization.</p></li>
</ul>
</section>
<section id="cutmix">
<h2>Cutmix<a class="headerlink" href="#cutmix" title="Permalink to this heading">#</a></h2>
<p><strong>Cutmix</strong> combines two images by cutting a patch from one image and pasting it into another, while mixing their labels proportionally.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: Similar to Mixup, it promotes learning more robust features and improves generalization by providing more varied training examples.</p></li>
</ul>
</section>
<section id="weight-decay-tuning">
<h2>Weight Decay Tuning<a class="headerlink" href="#weight-decay-tuning" title="Permalink to this heading">#</a></h2>
<p><strong>Weight Decay Tuning</strong> involves adjusting the regularization parameter that penalizes large weights to prevent overfitting.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: Proper weight decay tuning helps in controlling the complexity of the model, leading to better generalization.</p></li>
</ul>
</section>
<section id="fixres-mitigations">
<h2>FixRes Mitigations<a class="headerlink" href="#fixres-mitigations" title="Permalink to this heading">#</a></h2>
<p><strong>FixRes (Fixed Resolution) Mitigations</strong> involve adjusting the resolution of input images during different stages of training and testing to improve accuracy.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It helps in training models at higher resolutions, making them more robust to different scales and improving performance.</p></li>
</ul>
</section>
<section id="ema-exponential-moving-average">
<h2>EMA (Exponential Moving Average)<a class="headerlink" href="#ema-exponential-moving-average" title="Permalink to this heading">#</a></h2>
<p><strong>Exponential Moving Average (EMA)</strong> maintains a moving average of the model parameters during training.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: EMA can stabilize training and improve final model performance by averaging out the noise in parameter updates.</p></li>
</ul>
</section>
<section id="inference-resize-tuning">
<h2>Inference Resize Tuning<a class="headerlink" href="#inference-resize-tuning" title="Permalink to this heading">#</a></h2>
<p><strong>Inference Resize Tuning</strong> involves adjusting the size of input images at inference time to optimize performance.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: Properly tuning the input size can balance accuracy and computational efficiency, leading to better model performance during inference.</p></li>
</ul>
</section>
<section id="repeated-augmentation">
<h2>Repeated Augmentation<a class="headerlink" href="#repeated-augmentation" title="Permalink to this heading">#</a></h2>
<p><strong>Repeated Augmentation</strong> applies the same augmentation multiple times to the same image within a batch.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It increases the diversity of the training data seen by the model, enhancing robustness and generalization.</p></li>
</ul>
</section>
<section id="batch-normalization">
<h2>Batch Normalization<a class="headerlink" href="#batch-normalization" title="Permalink to this heading">#</a></h2>
<p><strong>Batch Normalization (BatchNorm)</strong> normalizes the activations of each layer for each mini-batch during training.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It reduces internal covariate shift, leading to faster convergence and higher stability during training.</p></li>
</ul>
</section>
<section id="dropout">
<h2>Dropout<a class="headerlink" href="#dropout" title="Permalink to this heading">#</a></h2>
<p><strong>Dropout</strong> randomly drops neurons during training to prevent overfitting.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: By randomly omitting neurons, dropout forces the network to learn more robust features and prevents overfitting.</p></li>
</ul>
</section>
<section id="gradient-clipping">
<h2>Gradient Clipping<a class="headerlink" href="#gradient-clipping" title="Permalink to this heading">#</a></h2>
<p><strong>Gradient Clipping</strong> involves capping the gradients during backpropagation to prevent the problem of exploding gradients.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It stabilizes training by ensuring that the gradient updates are not excessively large, which can otherwise destabilize training.</p></li>
</ul>
</section>
<section id="transfer-learning">
<h2>Transfer Learning<a class="headerlink" href="#transfer-learning" title="Permalink to this heading">#</a></h2>
<p><strong>Transfer Learning</strong> leverages pre-trained models on large datasets to initialize a model for a new task.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It speeds up training and often leads to better performance by starting with a model that already has learned useful features.</p></li>
</ul>
</section>
<section id="cosine-annealing">
<h2>Cosine Annealing<a class="headerlink" href="#cosine-annealing" title="Permalink to this heading">#</a></h2>
<p><strong>Cosine Annealing</strong> is a learning rate schedule that reduces the learning rate following a cosine function.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It allows the model to converge more smoothly by reducing the learning rate gradually and cyclically.</p></li>
</ul>
</section>
<section id="early-stopping">
<h2>Early Stopping<a class="headerlink" href="#early-stopping" title="Permalink to this heading">#</a></h2>
<p><strong>Early Stopping</strong> monitors the model’s performance on a validation set and stops training when performance stops improving.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It prevents overfitting by halting training once the model starts to overfit the training data.</p></li>
</ul>
</section>
<section id="warmup-learning-rate">
<h2>Warmup Learning Rate<a class="headerlink" href="#warmup-learning-rate" title="Permalink to this heading">#</a></h2>
<p><strong>Warmup Learning Rate</strong> starts training with a very small learning rate and gradually increases it to the initial value.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It helps in stabilizing training in the initial epochs, especially for very deep networks.</p></li>
</ul>
</section>
<section id="knowledge-distillation">
<h2>Knowledge Distillation<a class="headerlink" href="#knowledge-distillation" title="Permalink to this heading">#</a></h2>
<p><strong>Knowledge Distillation</strong> involves training a smaller, student model to mimic the outputs of a larger, teacher model.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: The student model can achieve competitive performance with reduced complexity and better generalization.</p></li>
</ul>
</section>
<section id="data-augmentation">
<h2>Data Augmentation<a class="headerlink" href="#data-augmentation" title="Permalink to this heading">#</a></h2>
<p><strong>Data Augmentation</strong> involves generating new training samples through transformations like rotation, scaling, and flipping.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It artificially enlarges the training dataset, helping the model generalize better by learning from more diverse examples.</p></li>
</ul>
</section>
<section id="autoaugment">
<h2>AutoAugment<a class="headerlink" href="#autoaugment" title="Permalink to this heading">#</a></h2>
<p><strong>AutoAugment</strong> is a data augmentation technique that uses reinforcement learning to find the best augmentation policies.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It automatically finds effective augmentation strategies that improve model performance.</p></li>
</ul>
</section>
<section id="stochastic-depth">
<h2>Stochastic Depth<a class="headerlink" href="#stochastic-depth" title="Permalink to this heading">#</a></h2>
<p><strong>Stochastic Depth</strong> randomly drops entire layers during training.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It acts as a form of regularization, making the network more robust and reducing overfitting.</p></li>
</ul>
</section>
<section id="ghost-batch-normalization">
<h2>Ghost Batch Normalization<a class="headerlink" href="#ghost-batch-normalization" title="Permalink to this heading">#</a></h2>
<p><strong>Ghost Batch Normalization</strong> splits a large batch into smaller “ghost” batches for batch normalization.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It reduces memory usage and makes training more stable, especially for very large batches.</p></li>
</ul>
</section>
<section id="label-propagation">
<h2>Label Propagation<a class="headerlink" href="#label-propagation" title="Permalink to this heading">#</a></h2>
<p><strong>Label Propagation</strong> uses unlabeled data by propagating labels from labeled data points.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It leverages both labeled and unlabeled data, improving the model’s performance in semi-supervised learning settings.</p></li>
</ul>
</section>
<section id="gradient-accumulation">
<h2>Gradient Accumulation<a class="headerlink" href="#gradient-accumulation" title="Permalink to this heading">#</a></h2>
<p><strong>Gradient Accumulation</strong> accumulates gradients over multiple mini-batches before performing an update.</p>
<ul class="simple">
<li><p><strong>How it helps</strong>: It allows the use of larger effective batch sizes without increasing memory requirements.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./00_ai24/cv/infer"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pyInter.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">pytorch Inference</p>
      </div>
    </a>
    <a class="right-next"
       href="zoo.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">zoo(s)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lr-optimizations">LR Optimizations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trivialaugment">TrivialAugment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#long-training">Long Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-erasing">Random Erasing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#label-smoothing">Label Smoothing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixup">Mixup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cutmix">Cutmix</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weight-decay-tuning">Weight Decay Tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fixres-mitigations">FixRes Mitigations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ema-exponential-moving-average">EMA (Exponential Moving Average)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-resize-tuning">Inference Resize Tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#repeated-augmentation">Repeated Augmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-normalization">Batch Normalization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dropout">Dropout</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-clipping">Gradient Clipping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">Transfer Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cosine-annealing">Cosine Annealing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#early-stopping">Early Stopping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#warmup-learning-rate">Warmup Learning Rate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-distillation">Knowledge Distillation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation">Data Augmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoaugment">AutoAugment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-depth">Stochastic Depth</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ghost-batch-normalization">Ghost Batch Normalization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#label-propagation">Label Propagation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-accumulation">Gradient Accumulation</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 0xsol
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>